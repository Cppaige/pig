import cv2
import os
import numpy as np
from pathlib import Path
from predict import PigPersonAnnotator


class VideoProcessorSimple:
    """ç®€åŒ–çš„è§†é¢‘å¤„ç†å™¨ - ç”Ÿæˆå›¾ç‰‡åºåˆ—è€Œä¸æ˜¯è§†é¢‘ï¼ˆæ›´å¯é ï¼‰"""

    def __init__(self, annotator):
        self.annotator = annotator

    def process_video_to_images(self, video_path, output_dir,
                               frame_skip=5,
                               conf_threshold=0.25,
                               enable_deduplication=True,
                               progress_callback=None):
        """
        å¤„ç†è§†é¢‘ï¼Œç”Ÿæˆæ ‡æ³¨åçš„å›¾ç‰‡åºåˆ—

        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            output_dir: è¾“å‡ºå›¾ç‰‡ç›®å½•
            frame_skip: å¸§é‡‡æ ·é—´éš”ï¼ˆ1=æ¯å¸§ï¼Œ5=æ¯5å¸§ï¼‰
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            enable_deduplication: æ˜¯å¦å¯ç”¨è·¨å¸§å»é‡
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            dict: å¤„ç†ç»“æœç»Ÿè®¡
        """
        # æ›´æ–° annotator å‚æ•°
        self.annotator.conf = conf_threshold
        self.annotator.enable_deduplication = enable_deduplication

        # æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")

        # è·å–è§†é¢‘ä¿¡æ¯
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        if fps == 0 or not fps:
            fps = 25.0

        print(f"è§†é¢‘ä¿¡æ¯: {fps} fps, {total_frames} å¸§")
        print(f"å¤„ç†è®¾ç½®: é‡‡æ ·é—´éš”={frame_skip}, ç½®ä¿¡åº¦={conf_threshold}, å»é‡={enable_deduplication}")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_frames': total_frames,
            'processed_frames': 0,
            'total_pigs': 0,
            'total_persons': 0,
            'frame_results': [],
            'output_dir': output_dir,
            'fps': fps,
            'frame_skip': frame_skip,
            'dedup_enabled': enable_deduplication
        }

        # è·¨å¸§å»é‡ï¼šè®°å½•æ¯åªçŒªçš„ä¸­å¿ƒç‚¹å’Œè¾¹ç•Œæ¡†
        tracked_pigs = []
        TRACKING_IOU_THRESHOLD = 0.3  # IoU é˜ˆå€¼
        TRACKING_DISTANCE_THRESHOLD = 50  # è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰- æ›´ä¿å®ˆ
        MAX_TRACKING_AGE = 30 * frame_skip  # æœ€å¤§è·Ÿè¸ªå¸§æ•°ï¼ˆé¿å…è¯¯åˆ¤ï¼‰

        # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜å‚¨å¸§
        temp_dir = os.path.join(output_dir, 'temp_frames')
        os.makedirs(temp_dir, exist_ok=True)

        # IoU è®¡ç®—å‡½æ•°
        def calculate_iou(box1, box2):
            """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„ IoU"""
            x1_min, y1_min, w1, h1 = box1
            x2_min, y2_min, w2, h2 = box2

            x1_max = x1_min + w1
            y1_max = y1_min + h1
            x2_max = x2_min + w2
            y2_max = y2_min + h2

            # è®¡ç®—äº¤é›†
            inter_x_min = max(x1_min, x2_min)
            inter_y_min = max(y1_min, y2_min)
            inter_x_max = min(x1_max, x2_max)
            inter_y_max = min(y1_max, y2_max)

            if inter_x_max < inter_x_min or inter_y_max < inter_y_min:
                return 0.0

            inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)

            # è®¡ç®—å¹¶é›†
            box1_area = w1 * h1
            box2_area = w2 * h2
            union_area = box1_area + box2_area - inter_area

            if union_area == 0:
                return 0.0

            return inter_area / union_area

        try:
            frame_count = 0
            processed_count = 0

            while True:
                ret, frame = cap.read()

                if not ret:
                    break

                frame_count += 1

                # å¸§é‡‡æ ·ï¼šåªå¤„ç†æ¯éš” N å¸§
                if frame_count % frame_skip != 0:
                    continue

                # ä¿å­˜å½“å‰å¸§ä¸ºä¸´æ—¶å›¾ç‰‡
                temp_frame_path = os.path.join(temp_dir, f'frame_{frame_count:06d}.jpg')
                cv2.imwrite(temp_frame_path, frame)

                # ä½¿ç”¨ annotator è¿›è¡Œæ£€æµ‹å’Œå¯è§†åŒ–
                try:
                    annotated_frame, coco_result = self.annotator.visualize(
                        temp_frame_path,
                        output_path=None
                    )

                    # ç»Ÿè®¡å½“å‰å¸§çš„æ£€æµ‹ç»“æœ
                    annotations = coco_result.get('annotations', [])

                    # è·¨å¸§å»é‡é€»è¾‘
                    unique_pig_count = 0
                    unique_person_count = 0

                    for ann in annotations:
                        category_name = ann.get('category_name', '')
                        bbox = ann.get('bbox', [])  # [x, y, width, height]

                        if category_name == 'pig' and len(bbox) == 4:
                            # è®¡ç®—ä¸­å¿ƒç‚¹
                            center_x = bbox[0] + bbox[2] / 2
                            center_y = bbox[1] + bbox[3] / 2

                            if enable_deduplication:
                                # æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰çš„çŒªåŒ¹é…
                                matched = False

                                for tracked in tracked_pigs:
                                    # æ–¹æ³•1ï¼šè®¡ç®— IoUï¼ˆæ›´å‡†ç¡®ï¼‰
                                    iou = calculate_iou(bbox, tracked['bbox'])

                                    # æ–¹æ³•2ï¼šè®¡ç®—ä¸­å¿ƒç‚¹è·ç¦»
                                    tracked_center = tracked['center']
                                    distance = np.sqrt((center_x - tracked_center[0])**2 +
                                                     (center_y - tracked_center[1])**2)

                                    # ç»¼åˆåˆ¤æ–­ï¼šIoU é«˜ æˆ– è·ç¦»è¿‘ = åŒä¸€åªçŒª
                                    if iou > TRACKING_IOU_THRESHOLD or distance < TRACKING_DISTANCE_THRESHOLD:
                                        # æ›´æ–°è·Ÿè¸ªè®°å½•ï¼ˆä½¿ç”¨æ–°çš„ä½ç½®ï¼‰
                                        tracked['bbox'] = bbox
                                        tracked['center'] = (center_x, center_y)
                                        tracked['frame'] = frame_count
                                        matched = True
                                        break  # æ‰¾åˆ°åŒ¹é…å°±åœæ­¢

                                if matched:
                                    # åŒ¹é…åˆ°äº†å·²æœ‰çš„çŒªï¼Œè¯´æ˜è¿™æ˜¯åŒä¸€åªçŒªåœ¨åç»­å¸§ä¸­è¢«å†æ¬¡æ£€æµ‹åˆ°
                                    # å…³é”®ï¼šä¸é‡å¤è®¡æ•°ï¼åªè®°å½•ä¸€æ¬¡
                                    pass
                                else:
                                    # æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å·²æœ‰çš„çŒªï¼Œæ˜¯æ–°çŒª
                                    tracked_pigs.append({
                                        'bbox': bbox,
                                        'center': (center_x, center_y),
                                        'frame': frame_count
                                    })
                                    unique_pig_count += 1  # åªæœ‰æ–°çŒªæ‰è®¡æ•°
                            else:
                                unique_pig_count += 1

                        elif category_name == 'person':
                            unique_person_count += 1

                    # æ¸…ç†è¿‡æœŸçš„è·Ÿè¸ªè®°å½•ï¼ˆé¿å…è¯¯åˆ¤ï¼‰
                    if enable_deduplication and processed_count % 10 == 0:
                        current_frame = frame_count
                        tracked_pigs = [
                            t for t in tracked_pigs
                            if current_frame - t['frame'] < MAX_TRACKING_AGE
                        ]

                    stats['total_pigs'] += unique_pig_count
                    stats['total_persons'] += unique_person_count

                    # åœ¨å¸§ä¸Šæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                    dedup_note = " (å»é‡)" if enable_deduplication else ""
                    info_text = f"Frame: {frame_count}/{total_frames} | Pigs: {unique_pig_count}{dedup_note} | Persons: {unique_person_count}"
                    annotated_frame_bgr = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)
                    cv2.putText(
                        annotated_frame_bgr,
                        info_text,
                        (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.8,
                        (0, 255, 0),
                        2
                    )

                    # ä¿å­˜æ ‡æ³¨åçš„å›¾ç‰‡
                    output_frame_path = os.path.join(output_dir, f'annotated_frame_{processed_count:06d}.jpg')
                    cv2.imwrite(output_frame_path, annotated_frame_bgr)

                    # è®°å½•å¸§ç»“æœ
                    stats['frame_results'].append({
                        'frame_number': frame_count,
                        'pig_count': unique_pig_count,
                        'person_count': unique_person_count,
                        'total_objects': unique_pig_count + unique_person_count,
                        'image_path': f'annotated_frame_{processed_count:06d}.jpg'
                    })

                    # æ›´æ–°è¿›åº¦
                    stats['processed_frames'] = processed_count
                    processed_count += 1

                    if progress_callback:
                        progress_callback(frame_count, total_frames, temp_frame_path)

                    if frame_count % 50 == 0:
                        print(f"å·²å¤„ç† {frame_count}/{total_frames} å¸§ï¼Œç”Ÿæˆ {processed_count} å¼ å›¾ç‰‡")

                except Exception as e:
                    print(f"å¤„ç†å¸§ {frame_count} æ—¶å‡ºé”™: {str(e)}")

                # æ¸…ç†ä¸´æ—¶å¸§æ–‡ä»¶
                if os.path.exists(temp_frame_path):
                    os.remove(temp_frame_path)

        finally:
            # æ¸…ç†
            cap.release()

            # åˆ é™¤ä¸´æ—¶ç›®å½•
            if os.path.exists(temp_dir):
                for file in os.listdir(temp_dir):
                    os.remove(os.path.join(temp_dir, file))
                os.rmdir(temp_dir)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if len(stats['frame_results']) > 0:
            avg_pigs = stats['total_pigs'] / len(stats['frame_results'])
            avg_persons = stats['total_persons'] / len(stats['frame_results'])

            print(f"\n{'='*50}")
            print(f"{'è§†é¢‘å¤„ç†å®Œæˆ':^40}")
            print(f"{'='*50}")
            print(f"æ€»å¸§æ•°: {total_frames}")
            print(f"é‡‡æ ·é—´éš”: æ¯ {frame_skip} å¸§")
            print(f"ç”Ÿæˆå›¾ç‰‡: {len(stats['frame_results'])} å¼ ")
            print(f"-" * 50)
            print(f"{'ç»Ÿè®¡ç»“æœï¼ˆå·²å¯ç”¨è·¨å¸§å»é‡ï¼‰':^40}")
            print(f"-" * 50)
            print(f"æ£€æµ‹åˆ°çš„çŒªæ€»æ•°ï¼ˆå»é‡åï¼‰: {stats['total_pigs']} åª")
            print(f"å¹³å‡æ¯å¼ å›¾ç‰‡çŒªæ•°é‡: {avg_pigs:.2f} åª")
            print(f"æ£€æµ‹åˆ°çš„äººæ€»æ•°: {stats['total_persons']} ä¸ª")
            print(f"å¹³å‡æ¯å¼ å›¾ç‰‡äººæ•°é‡: {avg_persons:.2f} ä¸ª")
            print(f"-" * 50)
            print(f"\nğŸ’¡ ç»“æœè§£è¯»:")
            print(f"   - çŒªæ€»æ•°ä»£è¡¨è§†é¢‘ä¸­æ£€æµ‹åˆ°çš„æ‰€æœ‰ä¸åŒçš„çŒª")
            print(f"   - å¦‚æœæ•°é‡ä»ç„¶åé«˜ï¼Œå»ºè®®ï¼š")
            print(f"     1. å‡å°é‡‡æ ·é—´éš”ï¼ˆæ”¹ä¸ºæ¯ 5-10 å¸§ï¼‰")
            print(f"     2. æé«˜ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆæ”¹ä¸ºé«˜ 0.40ï¼‰")
            print(f"     3. æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡è¿›è¡Œäººå·¥æ ¸å¯¹")
            print(f"{'='*50}\n")

        return stats
